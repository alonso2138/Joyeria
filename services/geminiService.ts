import { GoogleGenAI, Modality } from "@google/genai";

// Helper to convert an image URL to the format required by the Gemini API
const urlToInlineData = async (url: string) => {
    const response = await fetch(url);
    if (!response.ok) {
        throw new Error(`Failed to fetch image from ${url}: ${response.statusText}`);
    }
    const blob = await response.blob();
    const mimeType = blob.type;

    const base64Data = await new Promise<string>((resolve, reject) => {
        const reader = new FileReader();
        reader.onloadend = () => resolve((reader.result as string).split(',')[1]);
        reader.onerror = reject;
        reader.readAsDataURL(blob);
    });

    return {
        inlineData: {
            data: base64Data,
            mimeType,
        },
    };
};

const userImageToInlineData = (base64String: string) => {
    // The incoming string is 'data:image/jpeg;base64,xxxxxxxx'
    const [header, data] = base64String.split(',');
    const mimeType = header.match(/:(.*?);/)?.[1] || 'image/jpeg';

    return {
        inlineData: {
            data,
            mimeType,
        },
    };
};


/**
 * Generates a virtual try-on image using the Gemini 'gemini-2.5-flash-image' model.
 *
 * @param userImageBase64 The base64 encoded string of the photo taken by the user.
 * @param jewelryOverlayUrl The URL of the transparent PNG asset of the jewelry to be overlaid.
 * @returns A promise that resolves to a base64 URL of the final composed image.
 */
export const generateTryOnImage = async (
  userImageBase64: string,
  jewelryOverlayUrl: string
): Promise<string> => {
  console.log('GEMINI SERVICE: Initiating virtual try-on with gemini-2.5-flash-image.');

  console.log(import.meta.env.VITE_API_KEY)

  try {
    const ai = new GoogleGenAI({ apiKey: import.meta.env.VITE_API_KEY });

    // Prepare the images and the prompt for the model
    const userImagePart = userImageToInlineData(userImageBase64);
    const jewelryImagePart = await urlToInlineData(jewelryOverlayUrl);
    const textPart = {
        text: `Simulate a virtual try-on. Realistically place the second image (a piece of jewelry with a transparent background) onto the first image (a person). The jewelry should be positioned where it would naturally be worn. For example, a ring goes on a finger, a necklace on the neck, an earring on an earlobe, etc. Maintain the original lighting and perspective as much as possible.`
    };

    const response = await ai.models.generateContent({
        model: 'gemini-2.5-flash-image',
        contents: {
            parts: [userImagePart, jewelryImagePart, textPart],
        },
        config: {
            responseModalities: [Modality.IMAGE],
        },
    });

    // Extract the generated image from the response
    for (const part of response.candidates[0].content.parts) {
        if (part.inlineData) {
            const base64ImageBytes: string = part.inlineData.data;
            const mimeType = part.inlineData.mimeType;
            console.log('GEMINI SERVICE: Virtual try-on image generated successfully.');
            return `data:${mimeType};base64,${base64ImageBytes}`;
        }
    }
    
    throw new Error("No image was generated by the model.");

  } catch (error) {
    console.error("Error during Gemini API call:", error);
    // Return a placeholder or throw the error to be handled by the UI
    // Using a static image from picsum to represent an error.
    return 'https://picsum.photos/seed/tryon-error/800/1200';
  }
};